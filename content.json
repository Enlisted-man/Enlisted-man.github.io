{"pages":[{"title":"","text":"1ed37f2481c7f2944c0533105f81b85b","link":"/baidu_verify_code-Zo4SdQ1SO4.html"},{"title":"About","text":"Welcome to Enlisted-man’s blog.","link":"/about/index.html"},{"title":"tags","text":"","link":"/tags/index.html"},{"title":"categories","text":"","link":"/categories/index.html"}],"posts":[{"title":"Bottleneck-LSTM-CVPR2018-VideoDetection","text":"Bottleneck-LSTM-2018 Bottleneck-LSTM：Mobile Video Object Detection with Temporally-Aware Feature Paper: https://arxiv.org/abs/1711.06368 Code: https://github.com/tensorflow/models/tree/master/research Overview 构建Conv Bottleneck-LSTM，并将Bottleneck-LSTM与one stage检测相结合。其中，Bottleneck-LSTM借鉴了深度可分离卷积和bottleneck。 在video detection中的速度，相比现存检测算快，FPS为15（个人感觉比较慢）。 why 现存常规的检测器，针对视频检测速度较慢，无法达到实时。 有一部分没有考虑视频检测中的时序信息。 同时部分使用光流的方法存在速度较慢的劣势。 使用LSTM的方法并没有将LSTM和卷积网络完全融合。 LRCNs将每帧的feature序列输入LSTM ROLO使用YOLO做检测，然后将检测的BBox和feature送入到LSTM what 使用CNN提取图像特征，然后将特征送入convolutional LSTM进行历史帧特征融合（记忆重要信息，特征结合），输出。 how 大体思路。使用前t帧的图像，前t-1帧的feature，来获取当前帧的bboxes和分类置信度。 F(I_t,S_t-1) = (D_t , S_t)其中，I_t表示第t帧的视频序列，S_t-1表示前t-1帧的feature，D_t表示相对于I_t帧的bboxes和confidences集合2. LSTM-SSD中SSD的网络结构更换为MobileNet，并使用深度可分离卷积代替了所有的常规卷积。3. Bottleneck-LSTM。借鉴了深度可分离卷积，bottleneck。 Conv LSTM的定义。其中，M，N分别为LSTM输入/输出的通道数。LSTM将x_t和h_t-1(featue map)进行channel-wise操作，输出h_t和c_t，W(j,k)⭐X代表深度可分离卷积操作，j表示输入通道，k表示输出通道，o表示矩阵对应元素相乘，∮表示ReLU激活函数。 使用如下的b_t代替所有门的输入。 添加通道调整超参数a_base = a,a_lstm = 0.5a,a_ssd = 0.25a来分别控制不同网络模块通道维度，从而来控制网络的计算量。 优势：减少了标准LSTM中的计算；BottleNeck-LSTM的网络结构更深，效果更好。 具体实现 单个LSTM模块的网络结构。 首先finetune 无LSTM的SSD网络，freeze基准网络（到conv13）,然后在train的时候添加LSTM模块。最终在conv13之后的所有feature map后都添加了LSTM模块作为最终模型。 result 单个LSTM模块，mAP相对提升3.2% 单个LSTM模块，在参数量，和计算量方面的对比，大约可以减少10-20倍的参数量，减少20倍左右的计算量。其中MAC代表multi-adds。 多个LSTM模块，LSTM模块的重复堆叠没有提升，多层放置LSTM的效果会比单个放置提高0.9%，计算量不会有太大变化。","link":"/2019/05/21/Bottleneck-LSTM-CVPR2018-VideoDetection/"},{"title":"ATOM-CVPR2019-Tracking","text":"ATOM-2019 ATOM：Accurate Tracking by Overlap Maximization Paper ： https://arxiv.org/abs/1811.07628 Code ：https://github.com/visionml/pytracking Overview 大佬决定在跟踪精度上做改进，抛弃anchor，使用GT添加高斯噪声的方式。 受到IOUNet的启发，将class-special的IOU-Net改为target-special的IOU-Net使其适用于tracking的情境。 SGD算法收敛太慢，所以提出了新的收敛算法（共轭梯度+牛顿高斯）。 why 近年来，大家的目光都聚焦在tracking的鲁棒性上，而忽略了tracking的准确性。 在IOUNet的启发下作的一些改进。 what网络结构 target分类（online） 区分前/背景提供一个粗略的定位，online提高分类的鲁棒性 使用2层全连接层 抛弃SGD，使用共轭梯度+牛顿高斯方法优化 target估计（offline） 用于寻找overlap最大化的bbox，offline学习一个更通用的IoU预测表示 使用IOU-predictor网络来进行target估计 input是image object的feature和bbox_delta，然后使用PrROI pooling得到一个预定义大小的feature。 how 网络结构 backbone ：Resnet-18（在ImageNet上预训练） IOU Modulation 对reference帧和search帧进行了特征提取，之后通过channel-wise multiplication做特征融合。 IOU predictor 由3层FC层组成 IOU predictor input : 当前帧的feature，当前帧的bbox估计，reference帧的feature，reference帧中的target bbox IOU predictor output : 当前帧中预测的每一个bbox的iou值 Classifier 2个全卷积网络 第一层由1x1卷积构成，将通道减小至64，减少计算量。 第二层使用4x4的单输出通道kernel 使用PELU作为输出的激活函数，可以忽略掉简单的负样本 第一帧，使用了数据增强(旋转，模糊，dropout等) 在分类过程中使用了自定义的优化策略（共轭梯度+牛顿高斯） 实现细节 使用了LaSOT和TrackingNet数据集，同时使用了COCO数据集来进行数据增强操作 图像对采样间隔为50 每个图像对，对应生成16个候选的bbox（GT+高斯噪声，同时确保最小iou为0.1） 权重初始化 - Delving deep into rectiﬁers: Surpassing human-level performance on imagenet classiﬁcation. In ICCV, 2015. 5 loss使用MSE loss，训练40个epoch，每个epoch使用64个图像对 学习率初始为10e-3，weight decay factor为0.2（15epoch） 在训练过程中，backbone的weight被freezed 硬负样本挖掘，当distractor在分类score中取到峰值，会将该样本使用2倍的lr在优化训练一轮。同时，在score低于0.25时判断为丢失。 最后的输出使用IOU最高的3个bbox的平均值。 results Nvidia GT-1080 GPU上运行30FPS other points 低层包含更多的表面信息，那为什么不用底层feature做reg,用高层语义信息去做分类。","link":"/2019/05/25/ATOM-CVPR2019-Tracking/"},{"title":"C-RPN-CVPR2019-Tracking","text":"C-RPN-2019 Siamese Cascaded Region Proposal Networks for Real-Time Visual Tracking Paper：https://arxiv.org/abs/1812.06148?context=cs Code：https://github.com/zhu2014yi/CRPN Overview 通过级联RPN（多stages）筛选，解决了样本不平衡问题。(多阶段筛选) 构建FTB block用于高/低特征融合，结果更加精确。（多层融合） 其实跟SPM Tracker的出发点相同，都是针对Siamese网络中相似物体的drift问题，解决思想也相同，都是使用多stages过滤以获得更好的效果，但是整体来说效果离SPM差很多，首先多RPN肯定很耗时，FPS在36左右，同时精度提升也不是特别明显，VOT16上EAO为0.363。 why 针对Siamese自身存在的问题 – 相似物体的drift 样本不平衡问题 大多数样本为简单负样本 在现有的siamese网络中，低层的feature信息没有合理利用 高层的信息可能包含更多的语义信息，造成相似物体的drift what 提出级联RPN的网络结构，分为3个stages，每个stage都做分类和回归对上一阶筛选的proposals在进行refine，每个阶段都会逐渐过滤简单负样本，保留为下一个阶段保留难例负样本。 用FTB做高低特征融合。 how 网络结构如图。仍然使用AlexNet结构提取特征。 FTB结构如图。高层feature经过反卷积恢复尺度，然后与底层feature通过element-wise结合，最后对融合后的feature进行插值操作，为了确保最终所有的RPN都能对应相同的GT。 GT和各阶段RPN的计算。","link":"/2019/05/22/C-RPN-CVPR2019-Tracking/"},{"title":"Deepsort-CVPR2017-Tracking","text":"Deep Sort-2017 DeepSort：Simple Online and Realtime Tracking with a Deep Association Metric Paper：https://arxiv.org/abs/1703.07402 Code：https://github.com/nwojke/deep_sort Overview 在Sort的基础上整合了appearance信息，引入了深度信息 将计算复杂度较高放在了离线预训练阶段，在大规模reid的数据集上学习一个关联矩阵，在online阶段，在visual appearance阶段建立了一个mearsure to track的最近邻查询。 减少了ID switch Sort with Deep Association Metric跟踪处理 + 状态估计 使用八个维度值(cx，cy，r，h，vcx，vcy，vr，vh)来估计tracking的状态，同时假设kalman filter是恒定速度和线性观测模型。 对于每一个track，都要计算上次匹配成功后的帧数a。当再次关联的时候置为0，目的是通过计数找出目标消失的情况。当a &gt; 设定Aage时，我们认为该track在image中消失。对于未关联的detection，我们认为其为新出现的目标。这些目标在前3帧中被认为暂定状态，当这些新出现的track在他们出现的前三帧中未成功关联就被删除。 匹配问题 在kalman filter预测和detection状态之间的分配问题一般使用Hungarian算法。文章中在这里整合了运动信息，外观特征信息。 运动信息，通过计算kalman states和detection之间的马氏距离。这里有公式d(1)(i,j) = (dj −yi)T^Si−1(dj −yi)。马氏距离通过测量检测远离平均轨道位置的标准偏差的多少来考虑状态估计不确定性。之后通过x2分布来过滤一些不可能存在的关联，这里有公式b(1) i,j = 1[d(1)(i,j) ≤ t(1)]。其中的Mahalanobis的阈值t(1)设定为9.4877。 [注]以上的马氏距离可以无相机运动的时有较好的预测效果。但是在相机快速运动，遮挡的情况下，Mahalanobis距离相当不准确。 外观特征，对于每一个detection dj提取外观特征，表示为rj，且||rj|| = 1，我们为每一个track维护它的最近Lk = 100个特征。第二个度量是计算track_i和detection_j在外观特征上的cosine distance。之后再通过x2分布进行过滤。 [注]同一物体在不同image中生成的feature向量的余弦距离是很小的。 lamda*运动信息 + (1-lamda)外观特征。运动信息适合短期预测，外观特征适合长期预测。在paper中，将lamda设为0，但是mahalanobis gate仍然被用来判断不可行的预测结果。 级联匹配 原因：在物体长时间遮挡的情况下，kalman预测会增加物体位置预测的不确定性。概率会在状态空间发散，可能无法观察。且当两个track被关联为同一个detection，mahalanobis distance偏向于不确定性更大的track，因为它有效地减少了任何检测的标准偏差与投影轨道平均值之间的距离。因此，采用级联的方式设定优先级。 级联匹配，优先考虑最小age的track。 在最终的match阶段，统计未确认，和age为1的未匹配的track。这个操作有助于对突然的外观变化等增加一定的鲁棒性。 深度外观描述子 使用最近邻查询，所以要提取较好的具有判别力的特征。文章中使用CNN在大规模的reid数据集上进行训练。 CNN网络结构使用resnet，两个conv layer加六个res blocks。最后在dense layer计算出来128维的特征映射。","link":"/2019/05/20/DeepSort-CVPR2017-Tracking/"},{"title":"Faster-RCNN-NIPS2015-Detection","text":"Faster-rcnn-NIPS2015 Faster RCNN：Towards Real-Time Object Detection with Region Proposal Networks Paper：https://arxiv.org/abs/1506.01497 Code ：https://github.com/chenyuntc/simple-faster-rcnn-pytorch 参考：https://zhuanlan.zhihu.com/p/32404424 Overview 使用RPN代替了耗时的selective search操作。 大致过程如下图。特征提取，RPN提取ROI（二分类+回归），ROI Head（多分类+回归） why 基于selective search的方法速度太慢。 二阶段（粗细粒度的筛选），可以使得检测的精度极大提升。 what 主要贡献在于，使用RPN替代了selective search方法。 Faster RCNN可主要分为三个阶段。 阶段一，特征提取。 阶段二，使用RPN提取ROIs，并对其中部分样本（256）进行二分类和回归，NMS过滤。 阶段三，使用ROI Pooling，对ROIs中的部分ROI进行Pooling操作统一到相同尺度，在做分类和回归，NMS过滤。 how Faster RCNN主要分三步：特征提取，RPN提取ROIs（二分类+回归），ROI Head/Pooling（多分类+回归）Feature Extractor 一般使用与训练好的VGG16，前4层的卷积的学习率设为0（为节省显存），Conv5_3的feature作为输出；VGG最后的三层全连接层的前两层，一般用来初始化RoIHead的部分参数。RPN 每个位置使用的anchor个数为9个，所以整张图大概会生成20000个anchors。 RPN结构3x3的卷积不太清楚什么用意？后接两个1x1的卷积分别用于二分类（9x2）和位置回归（9x4）。 AnchorTargetCreatorRPN利用AnchorTargetCreator从20000个anchor中选取256个做分类和回归。 计算所有anchors与GT的iou，每个GT对应IOU最高的anchor作为正样本。 其余样本随机选择与GT的iou大于阈值0.7的样本作为正样本。 随机选择与GT的iou小于阈值0.1的样本作为负样本。正负样本的比例大概为1：1，总数为256。 ProposalCreatorRPN利用ProposalCreator生成ROIs。 计算20000个anchors属于前景的概率，对应的位置参数 选取概率较大的12000个anchors，利用回归的位置参数修正这些anchors 使用NMS，选择出anchors最大的2000个ROIs inference时候，12000，2000分别对应6000，300 损失计算 分类损失，使用交叉熵。 回归损失，使用Smooth L1 lossROI Head/pooling ProposalTargetCreator ROIs和GT的iou大于0.5的选择32个。 ROIs和GT的iou小于0/1的选择96个。 ROI Pooling在RPN提供的2000个ROIs上，首先使用ProposalTargetCreator挑选128个ROIs，然后使用ROI Pooling将其pooling到统一的尺寸（128x512x7x7，ROI pooling是为了共享权重），继续进行分类和回归。FC21用来分类，20+1背景；F84用来回归，21x4。 损失计算 分类，交叉熵；回归，Smooth L1 loss 回归，只对ROI中的正样本计算loss 小结 RPN阶段是前/背景的二分类，ROIHead是21分类 RPN阶段，ROIHead阶段都做了NMS RPN阶段，ROIHead阶段都进行了回归Loss 4种损失加权求和 RPN分类/回归损失，ROI分类/回归损失 result mAP为0.699，fps为5","link":"/2019/05/14/Faster-RCNN-NIPS2015-Detection/"},{"title":"GARPN-CVPR2019-Detection","text":"GARPN-2019 GARPN：Region Proposal by Guided Anchoring Paper：http://arxiv.org/abs/1901.03278 Code：https://github.com/open-mmlab/mmdetection Overview 先前的anchor是在feature map上的每个点都设定(均匀分布)，本文的思想是先预测最有可能出现object中心的区域，然后在该区域进行anchor w h的预测，从而确定了anchors，减少了计算量。 anchor和feature map的匹配问题，根据anchor shape计算deformable conv的offset，从而对feature map进行变换，以生成新的feature map。 在新的feature map上进行分类和回归。 在resnet50-fpn作为backbone，其recall(AR)提高了9.1个点，mAP提高了1.2-2.7个点。 why 之前的anchor尺度/比例(超参)需要人为设定，设定不好对性能影响较大。 前anchor方法中的大多数anchor都分布在背景区域，对于proposal没有作用，徒增计算量。 数据集中的object形变较大，预定义的anchor不一定能满足其object尺寸。 所有。出现了本文稀疏，形状可变的anchor。 what p(x,y,w,h|I) = p(x,y|I)p(w,h|x,y,I)将anchor的坐标概率分布分为两个条件概率，即先进行anchor的位置预测，再进行形状预测。 how 网络结构 网络细节 主要为两部分：anchor生成+feature调整 anchor生成部分：F1(feature map)通过N_L分支预测anchor location,通过N_s预测anchor shape。 feature adaption:使用anchor信息生成可变形卷积的offset，在使用可变形卷积对feature map进行调整，以生成新的feature map。 anchor定位预测 二分类问题 在feature map上预测可能出现object中心点的位置(对应原图的一区域)，该中心区域为正样本，超出gt的区域作为负样本，gt和中心区域的部分忽略。 N_L子网络，在feature map上使用1x1卷积计算出一个score map,再使用sigmoid将score转换为概率。 anchor形状预测 回归问题 该部分使用IOU loss。设定了几组常见的w,h,然后计算anchors与所有gt的IOU,然后将该anchor分配给IOU最大的gt。 w = σ·s·e_dw, h = σ·s·e_dhN_s子网络预测输出dw,dh；dw,dh通过上式进行变换得到w,h。其中，s为stride，σ为经验比例因子(文中设定为8)。 原来直接预测w,h(范围在[0,1000]),现在通过预测dw,dh(范围在[-1,1])经e后可达到原先效果 特征适配 N_t子网络(使用3x3的可变卷积),根据anchor shape预测deformable conv的offset(offset是通过anchor的w和h经过一个1x1conv得到的),去做一个feature map的变换，以得到新的feature map。 在新的feature map上进行分类和回归。 FA提升了近5个点。 Tricks 减少proposal的数量 增大训练时正样本IOU阈值(重要，提升了2.7个点) others缺点 论文假设图像中的目标是稀疏的。如果是稠密图像，比如车站或广场的拥挤人群，检测效果有待检验。 每一个点只产生一个anchor，那么对于那些目标中心重合，即一个点需要负责检测两个目标，似乎无法处理。 采用deformable卷积会相对地降低速度，同时根据DCN v2的分析，在deformable卷积中加入可调节的机制可能会更好。 可形变卷积 Deformable conv简介-CVPR2017 评价标准 R(recall): 查全率，R = 预测出的正样本/原数据集中的所有正样本 AR : 平均查全率 P(precision)：查准率，P = 预测中的正样本/预测出的所有样本 AP : 平均查准率","link":"/2019/05/17/GARPN-CVPR2019-Detection/"},{"title":"GIOU-CVPR2019-Detection","text":"GIOU-2019 GIOU：Generalized-Intersection-over-Union Paper：https://arxiv.org/abs/1902.09630 Code：https://github.com/generalized-iou/g-darknet Overview 提出新的loss指标GIOU,使用评价标准作为loss，同时避免了IOU作为loss的缺点，有较好的提升。 在anchor较少的detection中有较为明显的提升(3-6个点) why 大家都在模型，trick上下功夫，忽略了在L1/L2上的改进(L_n范数对物体的scale比较敏感)。 直接使用iou作为loss存在的问题。 两个框没有相交，IOU=0，loss = 0,无法进行梯度的反向传播，无法学习训练。 IOU无法精确衡量重叠程度，且IOU的变化无法反馈定位框的重合度和方向。如下图。 how 设定gt为A，pred为B，先求包含A，B的最小闭包C。 计算C中去除A∪B后剩下的面积D，即D = C\\(A∪B)。 计算IoU GIoU = IoU - D/C IOU ∈ [0,1]，GIOU ∈ [-1,1] others 起初自己也想过使用iou作为loss，但是看到网上说iou作为loss可能存在梯度无法回传问题时，没有多思考去寻找解决办法。所以，遇到问题深究原因，考虑有没有可替代的近似方案。 IOU既然对于尺度不敏感，L_n对尺度敏感，那两者就可以做loss的结合。","link":"/2019/05/16/GIOU-CVPR2019-Detection/"},{"title":"SPM-CVPR19-Tracking","text":"SPM SPM-Tracker: Series-Parallel Matching for Real-Time Visual Object Tracking Paper：https://arxiv.org/abs/1904.04452v1 Code：https://github.com/microsoft/SPM-Tracker Overview 将Tracking中的两个需求（Robustness，deiscrimination）分别放在两个阶段（two-stage：CM-&gt;FM）实现。 感觉效果惊人！OTB-100上的AUC为0.687，VOT-16上的EAO竟然达到了0.434，GPU上的fps为120，牛！ 抓住了siamese网络的缺点(相似物体容易drift)，解决方式就是在一阶段CM提取目标物体和其相似物体作为正样本，在二阶段FM在仔细区分object和其相似物体，也算是在image中尽可能多的提炼信息。 why 在tracking的过程中，既要求tracker有足够的判别力(针对相似物体或者相似背景等)，又需要足够的鲁棒性(对于物体的形变，光照等)。但是用一阶段的方法学习两种能力，其间会相互影响。 现存的tracker速度太慢。 what 将Tracking分为两阶段来做，分别是CM，FM。CM负责鲁棒性，FM负责判别力。两阶段的融合省去了做多尺度测试。 在CM阶段同一类物体都被作为同一物体，来提高CM的鲁棒性。在FM阶段通过距离学习子网络替代了cross corrrelation来提高网络的判别力。CM的输出作为FM的输入，最终的输出是两阶段的融合。 SPM的优势 two-stage，容易train CM的输出作为FM的输入，正负样本的比例和难样本得到了平衡 两个阶段输出的融合可以有更高的精度 FM阶段有较少的proposals，省去了cross-correlation操作，改为使用trainable distance measure how 网络结构 特征提取：Siamese Alexnet(在ImageNet上预训练) CM Stage使用SiamRPN的网络结构，最小化类内特性，专注于robust ROI Align用来为每个proposal生成固定长度的区域特征 FM Stage为距离学习网络，最大化不同物体间的特性，专注于discrimination 最终输出为两阶段decision的融合(score + bbox deltas) CM阶段 将image中同类物体的中心区域（红，绿）都作为正样本，蓝色区域为忽略区域 FM阶段 该阶段的重点在于将CM阶段过滤后的object与背景/相似物体区分开 经CM过滤后剩余较少的proposal，所以丢弃了cross correlation操作，使用了新的关系网络来进行距离计算。 对于每一个proposal，直接从feature map上crop然后使用ROI pooling生成固定大小的feature，同时将高低层的信息concatenation。 关系网络的输入是图像对concatenate的feature信息，后接1x1卷积，再接2个全连接层（256个neurons），用来cls和box regression 融合 最终CM,FM阶段的scores和bbox deltas进行加权融合 other points CF-based执行必不可少的是在线更新策略，但是结合deep learning是特别慢的，所以researcher使用static discriminative trackers，像siamFC等。 SiamRPN使用RPN在提高bbox regression方面做了改进，DaSiamRPN使用样本策略(相似的同类物体作为正样本提高robust，语义信息接近的不同类物体作为负样本提高distrimination)在discrimination方面做了提升。 网络细节 在使用的AlexNet中保留了padding，因为ROI align需要feature和source image的像素对齐。 CM阶段使用no padding的中心feature(应该是从padding后的feature上crop下来) 每个ROI pooling后的feature大小为6x6x640 train细节 IOU 大于0.6，小于0.3的样本被保留。 loss :两个阶段，四个loss的加权和， cls : cross entropy , reg : smooth l1 loss","link":"/2019/05/19/SPM-CVPR2019-Tracking/"},{"title":"MGVD-CVPR2019-VideoDetection","text":"Memory-Guided-Video-Detection-2019 Looking Fast and Slow: Memory-Guided Mobile Video Object Detection Paper: https://arxiv.org/abs/1903.10172 Code: https://github.com/tensorflow/models/tree/master/research Overview 提出了memory-guided的多特征网络提取的网络结构，使用快/慢特征提取网络分别提取不同帧特征，可以减少冗余计算。 使用Double Q-learning强化学习策略来执行memory更新，进行特征提取网络的选择。 在移动设备上可以实现高精度，高速度（70fps）。 why 作者将video object detection大致分为三类。 后处理方法。使用单帧检测的方式，然后与前帧中的track进行数据关联。seq-nms通过动态编程和提高弱检测的置信度来进行跟踪。TCNN使用光流法来传播检测，同时使用跟踪算法寻找tubelets来重评分。缺点是仍然是在每帧上做检测。（看描述感觉是多目标跟踪） 特征流方法。将网络的中间特征通过光流方式传播。DFF在稀疏关键帧上进行检测，然后再其他所有帧上按照计算光流的方式进行传播。FGFA通过相邻帧与当前帧特征进行加权平均。 多帧方式。即同时对多帧做处理。D&amp;T做了检测和跟踪的结合，使用了ROI tracking和相邻帧loss的方法。STSN使用DCN来采样相邻帧特征。缺点是仍然需要高精度检测而不是直接使用之前帧的检测结果。 稀疏处理视频帧有很多方式，从固定间隔，到启发式策略。文中使用强化学习方式来构建关键帧选择策略。 what 交叉模型。使用memory guided策略，结合多个特征（大/小）提取网络，大/小网络在视频检测过程中交替使用。 使用DDQN强化学习策略来选取网络使用策略来进行memory更新。 how 交叉模型结构。多个特征提取器顺序或同时执行，提取的feature通过memory机制进行增强/调整。 memory模型。在LSTMs的基础上，对LSTM cell进行了三点改进，融合不同特征提取器的feature。 在bottleneck和output之间添加了skip connection。 使用channel-wise的方式，将LSTM state等分为G组，然后使用组卷积。 使用state skip update方法。相当于跳过f1的状态更新，直接使用之前f0的状态。这是因为LSTM中sigmoid的缺点，在多次更新之后几乎会完全遗忘之前的状态。 DDQN寻找自适应交叉策略 动作空间。包含m个动作。 状态空间。S = (ct,ht,ct − ct−1,ht − ht−1,ηt) ，当前LSTM的状态，状态的相对之前改变，动作的历史参数（长度为20的向量，运行的前k步是1，其余是0） 奖励函数。速度奖励 + 精度奖励，给出γ奖励。其中，L(Di)为使用feature_i做检测的loss。 DDQN的网络结构如下。 result","link":"/2019/05/24/MGVD-CVPR2019-VideoDetection/"},{"title":"KCF-TPAMI2014-Tracking","text":"KCF-2014 High-Speed Tracking with Kernelized Correlation Filters Paper:https://arxiv.org/abs/1404.7584 Code:https://github.com/foolwood/KCF Overview 相关滤波方向很经典的文章，果然还是数学思维是第一生产力中的核心。看了知乎上关于傅里叶变换的博文，很通透。 文章思想主要是，使用循环矩阵生成样本，使用相关滤波训练一个判别式分类器。 what 主要说负样本对模型训练十分重要，但是训练过程中负样本数量少，文中通过循环矩阵来生成样本。 通过带核函数的相关滤波来训练，使用快速傅里叶变换来加速计算。 KCF是在CSK（使用灰度图）上做的改进，引入了多通道特征（使用HOG替代了灰度图），核函数。 how 使用HOG替代了灰度特征 使用循环矩阵生成样本 使用核函数，快速傅里叶变换做加速","link":"/2019/05/18/KCF-TPAMI2014-Tracking/"},{"title":"SiamDW-CVPR2019-Tracking","text":"SiamDW SiamDW：Deeper and Wider Siamese Networks for Real-Time Visual Tracking Paper：http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_Deeper_and_Wider_Siamese_Networks_for_Real-Time_Visual_Tracking_CVPR_2019_paper.pdf Code：https://github.com/researchmm/SiamDW Overview 针对深度网络(如Resnet)无法在siamese网络取得很好的效果。SiamRPN++也是从这个点出发去做，两者的都找出了其影响最大的原因–padding，不过解决方式不同。 siamFC/siamRPN在VOT16上的EAO提升了23.3%和8.8% why 深度网络无法在siamese网络中取得很好的效果，对网络的各部分进行了分析，大体原因如下几点： 神经元感受野的增大会减小特征分辨和定位的精度 网络的padding会导致网络学习的位置偏见(主要因素) 网络stride what 基于残差bottleneck block进行了改进–cropping-inside residual ，用来crop(消除)padding的影响，同时可以控制感受野大小，网络的stride 几点说法 感受野：大的感受野能够把握target的结构信息，感受野太小不利于特征提取 Stride：影响定位精度，控制着输出feature的大小；输出feature的大小影响分辨和检测精度。 Padding：当物体移动到padding边缘，会产生一定的位置偏见 几点分析 网络越深，感受野就越大，理论上最后一层得感受野最大 Stride为4-8-16对应得变化为0.59-0.60-0.55(Alexnet),说明siamese更适合中等strdie(4,8)，随着网络深度的增加，stride不应该增加。 最优的感受野大概为image z的60%-80% 输出的feature大小较小的话，会降低track精度，因为小的feature没有组后的空间结构信息。 siamese训练的数据中object都在image的中心，所以当test数据中的object出现在image边缘时效果不好，且会受到边缘padding的影响。 how 基于resnet bottleneck改进–CIR Unit 在resnet block之后添加了crop operation，将block之后padding的最外层元素给crop掉。这样feature map岂不是会越来越小？ 下采样CIR-D 将stride由2设为1，并在block之后也加入了crop operation操作，之后又加了max pooling用于降采样 CIR多分枝结构 - CIR-Inception/CIR-NeXt CIR-Inception : 在short-connection部分加入了1x1卷积，并且通过concatenation来将两个分支的feature融合 CIR-ResNeXt : 将bottleneck分为了32个分支，最终通过addition融合 这两种结构后也接crop操作，去除padding影响。这两种复杂结构可以学习更加复杂的feature 最终，提到了crop之后feature map变小的解决方案–增大input image的大小，减小网络stride，surprise！？感觉应该有其他的方式来做padding比如说feature的均值填充之类的，没有试过不知道会不会有效果。 result 最好结果相对SiamRPN而言，提升了4个百分点，为0.301。 other points siamese网络的输入就是图像对，之前DaSiam就是在图像对这里使用的数据增强 如果我将z的信息提取hog或者就是feature特征，然后作为网络的input，在之后帧中判断其与之前的cosine distance,这种方案感觉也可行。","link":"/2019/05/23/SiamDW-CVPR2019-Tracking/"},{"title":"IOUNet-ECCV2018-Detection","text":"IOUNet-2018 Acquisition of Localization Confidence for Accurate Object Detection Paper : https://arxiv.org/abs/1807.11590 Code : https://github.com/vacancy/PreciseRoIPooling Overview 目前大多数的tracker都是通过cls score来确定物体的位置，但是分类得分高并不意味着定位的准确度高，所以用cls score去做NMS并不是特别合理，因为会把定位精准但分类得分低的卡掉。所以作者提出了使用iou score作为排序指标。 Paper提出了IOU-guided NMS，PrROI（使用积分的方式计算ROI特征）。 很有分量的文章，受益匪浅。 why 使用预测box的cls score去做NMS并不合理,如图所示。 根据皮尔逊相关系数，分类score和iou并不成正相关，而定位score和iou是成正相关。 并且，分类得分高的并不一定定位得分高，使用cls score做NMS会把这些定位得分高的box卡掉。 通过下图也可以看出，NMS很容易把IOU较高的bbox过滤掉（当然其中肯定存在大量的冗余bbox）。 传统的基于regression的bbox refine的问题。 regression-based和optimization-based的直观效果差距。 regression-based是通过回归[cx,cy,w,h]使其与gt尽可能接近。理论上不断refine会得到很精确的结果，但是cascad RCNN相关实验表示在随着refine次数的增加效果会下降，(为什么会这样还需要做点工作)。但是使用IOU的方式在不断refine后不会出现该情况。 what 提出了IOU-Net来预测bbox和gt的IOU值。 将ROI pooling/Align更换为prROI。 howIOU-Net IOU predictor的input是image通过FPN后的feature。output是每个bbox的iou score。这里使用的proposal并不是来自RPN，而是通过对GT进行随机变换（添加随机噪声等）得到的一系列proposals，然后对bbox进行过滤。对于每一个bbox会使用prROI-pooling在FPN上提取的feature，这些feature被送入2层fc层做IOU预测。 IOU-guided NMS 将NMS算法中的排序指标改为IOU score。 通过对iou进行聚类的方式对cls score进行更新(重点在第5,8行)。在根据iou过滤的过程中，将过滤掉的bboxes中的最高的cls score分配给当前的bbox，所以保留下的是其iou簇中最高的分类得分。感觉这样做的好处是消除iou一致情况下cls score的差别。 Optimization-based bbox refinement。IOU支路的梯度计算和参数更新 prROI pooling 上图是ROI pooling，ROI align，prROI pooling的对比，这是三种都是基于ROI坐标根据feature map提取feature的方法。 ROI pooling。 先将预测得到的ROI除以stride，并量化取整得到整数值的ROI 将ROI分为k*K个grid，每个grid的坐标为(x1,y1,x2,y2)，其坐标值不一定为整数，所以要量化取整，左上角向下取整，右下角向上取整，得到整数的坐标值。然后可以采用均值/最大值操作得到该grid的特征值。 优点：解决了不同大小ROI的尺寸不统一的问题 缺点：量化操作会引入一定的误差 ROI Align 对ROI pooling进行改进，直接使用浮点坐标值将ROI划分，消除了量化操作引入的误差。 对ROI的每个grid的坐标也不再进行量化，而是在grid中均匀取4个点，通过公式2（插值）计算得到该点的特征值（该公式根据距离对周围的4个点进行加权计算，距离越近权重越大），然后对其求平均 优点：消除了量化操作带来的误差 缺点：没有考虑grid的大小差异 PrROI pooling 使用积分的方式计算每个grid的特征值 ROI Align仅考虑该grid中4个插值点的均值，PrROI pooling是将grid中的值看做是连续的，通过对该grid中所有点求积分得到该grid所包围点的总和，最后除以面积。 优点：结果会更加精准 result IOU-guided NMS 当IOU threshold设定较高时，iou nms的效果会更加明显，因为threshold较高的时候需要bbox的坐标更加准确才会能更好的AP值。 optimization-based bbox refinement refinement在各个模块上都有不错的提升。 other pointsNMS 将所有的bbox按cls score降排序生成一个list 从top 1 bbox开始，计算该bbox与其他bbox的iou，若iou大于设定阈值则剔除。 再从top 2 bbox开始，计算该bbox与其他bbox的iou… 重复操作，直到list中所有元素都筛选完毕 soft NMS 并不是真正的抑制，而是对要过滤掉的bbox乘以一个衰减系数。 将所有的bbox按cls score降排序生成一个list 从top 1 bbox开始，计算该bbox与其他bbox的iou，若iou大于设定阈值则将其乘以一个系数，使其缩小，之后在重新比较。 再从top 2 bbox开始，计算该bbox与其他bbox的iou… 重复操作，直到list中所有元素都筛选完毕。 对于遮挡，目标密集的情况效果很好，但是对于稀疏的场景，召回率可能会低于NMS。 想法 对GT做随机调整这种方法，感觉可以用","link":"/2019/05/15/IOUNet-ECCV2018-Detection/"},{"title":"SSD-CVPR15-Detection","text":"SSD - 2015 SSD: Single Shot MultiBox Detector Paper：https://arxiv.org/pdf/1611.10012.pdf Code：https://github.com/amdegroot/ssd.pytorch Overview SSD与Yolo v1的对比 卷积检测。抛弃FC层采用卷积做检测。SSD每个检测框都对应输出一套独立的检测值。 多尺度特征图。采用多尺度特征图，大尺度检测小物体，小尺度检测大物体。 先验框。采用不同尺度/长宽比的先验框。 速度：58fps。mAP为72.1 why 针对Yolo v1存在的定位不精准，对小物体不友好等缺点的改进。 what one-stage检测。均匀地在图像上的不同位置，使用不同的尺度/长宽比进行采样，然后使用CNN提取特征后直接进行分类和回归。 SSD结合了卷积预测，多尺度特征，先验框来改进Yolo v1中存在的缺点。 how 网络结构 输入：300x300/512x512 网络结构①主干网络使用VGG16，分别将VGG16的全连接层fc6和fc7转换成conv6和conv7，移除dropout和fc8层，并增加了卷积层来获得更多的feature map。②Conv6使用扩展卷积，来扩大卷积的感受野。Conv6采用3x3大小但dilation rate=6的扩展卷积。 ③使用feature map大小分别为38，19，10，5，3，1。不同feature map上设定的先验框数目不同，分别为4，6，6，4，4。④随着特征图大小降低，先验框尺度线性增加。长宽比一般选取{1,2,3,1/2,1/3} 输出①检测值包含两个部分：类别置信度和边界框位置，各采用一次3x3卷积来进行完成。令nk为该特征图所采用的先验框数目，那么类别置信度需要的卷积核数量为nk x C ，而边界框位置需要的卷积核数量为nk x 4。②各个feature map对应：w x h x nk x (C+4) 真值 损失函数 位置损失 + 置信度损失。其中N为正样本数， 位置损失 置信度损失 - softmax loss 训练细节 先验框匹配①Yolo是gt所在单元格中与其IOU最大的那个作匹配。②第一步，SSD是找到每个gt与其最大的IOU作匹配，保证每一个gt都一定有一个先验框与之匹配。将匹配的bbox作为正样本，其余为负样本。第二步，将剩余先验框中与gts的iou大于阈值的进行匹配。匹配成功的都是正样本。③再采用hard negative mining，对负样本按照背景置信度误差进行抽样，选取误差最大的topk个，保证正负样本的比例为1：3。 使用了数据增强。裁剪，旋转，扭曲，随机采样等等。 result 数据增强，可以提高9个百分点（65.6 - 74.3）。 多尺度检测，可以提高12个百分点（62.4 - 74.6）。","link":"/2019/05/13/SSD-CVPR2015-Detection/"},{"title":"Yolov1-CVPR2015-Detection","text":"Yolo v1 - 2015 Yolo-v1：You Only Look Once, Unified, Real-Time Object Detection. Paper：https://arxiv.org/abs/1506.02640 Code: https://github.com/gliese581gg/YOLO_tensorflow Overview 经典的one-stage。直接对原图进行网格划分，将原图分为nxn的小块，然后通过卷积产生nxn的特征图，其一一对应，feature map上每个元素预测对应单元格内的分类/置信度/bbox偏移。 速度：155fps，mAP：63.4 why DPM采用不同大小和比例（宽高比）的窗口在整张图片上以一定的步长进行滑动，然后对这些窗口对应的区域做图像分类，来实现对整张图片的检测。DPM的缺点，目标大小未知，需要使用不同的大小/比例，步长，计算量很大。 RCNN使用selective search的方法仍然耗时。 what Yolo直接将image分成nxn的网格，然后根据卷积生成相同大小的feature map，feature map上每个元素预测对应单元格内的分类/置信度/bbox偏移。 how 网络结构 输入：448x448的image 划分为7x7的网格。 网络结构backbone：使用了24个卷积层，2个fc层训练过程中的网络结构。在googLenet之后添加了4个随机初始化权重的Conv层和2个fc层。 输出：7x7x30 其中30为20个类别概率，2个置信度，2个bbox的(x,y,w,h),其中，预测的x,y是中心坐标相对于左上角坐标的偏移量，单位是相对于单元格大小的；w，h是相对于整个图片的宽和高的比例；所以xy在[0,1]范围内。 预测tensor示意图。网络计算量：SxSx(Bx5+C) 损失函数 采用MSE损失函数，对于定位损失，分类损失分别采用不同的权重。定位损失使用较大的权重（5），然后分类损失权重分别为（0.5无object，1有object）。 其中，要各个大小bbox要同等对待，但是较小的边界框的误差更敏感，所以将网络bbox的w,h的预测改为了对其平方根的预测。 result 优点 简洁，速度较快，可以达到155fps，mAP为63.4 对整个image做conv，不容易对背景误判 缺点 每个单元格仅预测两个bbox，且共享一个类别，所以对密集物体判别不好。 定位不精准。 对小物体不友好，且无法定位比例不同寻常的物体。","link":"/2019/05/10/Yolov1-CVPR2015-Detection/"},{"title":"Yolov3-CVPR2018-Detection","text":"Yolo v3-2018 YOLOv3: An Incremental Improvement Paper：https://pjreddie.com/media/files/papers/YOLOv3.pdf Code：https://github.com/marvis/pytorch-yolo3 Overview 在Yolov2的基础上使用FPN结构，提升小目标检测的准确率。 提升backbone网络性能，backbone使用DarkNet-53。 为解决多标签分类问题，对象分类用Logistic取代了softmax。 why 针对Yolo v1/2中对小物体不友好的问题。 深层网络DarkNet-53替换。 为解决多标签分类问题，对象分类用Logistic取代了softmax what 使用FPN解决小物体检测问题。 DarkNet-19 + 残差结构实现深层网络结构替换。 loss更换。 how FPN Yolo v3在输入为416x416时，使用了3个尺度的特征图，52，26，13，feature map上每个点使用3个先验框，则先使用k-means获取9个box，再将这些box按照尺度大框小，尺度小框大的原则分别分配给3个特征图。 Darknet-53 loss 损失函数由v2的softmax loss替换为logistic loss softmax的归一化操作则意味着每个候选框只对应着一个类别，当预测的目标类别很复杂（多个相似类别）的时候，采用logistic regression进行分类，但是可以输出多个分类，比如说，男人，人。","link":"/2019/05/12/Yolov3-CVPR2018-Detection/"},{"title":"Yolov2-CVPR2017-Detection","text":"Yolo v2 2017 Yolo-v2（YOLO9000）: Better, Faster, Stronger Paper：https://arxiv.org/abs/1612.08242 Code: https://github.com/marvis/pytorch-yolo2 Overview 基于Yolo v1做了诸多改进。针对Yolo v1定位不精准，召回率低，对小物体不友好的问题，提出了位置限定预测，Anchor+卷积预测，pass-through操作等。 同时，引入了BN，高分辨率输入，边界框聚类分析，darnet-19，多尺度训练等，提高了检测性能。 最终在输入为544x544时，VOC07上mAP可达到78.6，相对应的fps为40（不同输入对应不同结果） why Yolo v1虽然检测速度很快，但是定位精度不准，物体定位不准确，召回率低，对小物体不友好，精度效果不如RCNN好。 what Batch Normalization 在Yolo v2中每一个卷积层之后，都添加BN层，抛弃Dropout。 BN可以提高模型的收敛速度，起到一定的正则化效果，防止模型过拟合。 使用BN后，mAP提高了2.4% 高分辨率输入 在Yolo v2中，使用448x448高分辨率输入，抛弃224x224低分辨率输入。 低分辨率不利于检测模型。因为在ImageNet上的预训练模型使用的为224x224的输入，在检测数据上使用448x448进行finetune效果不好；Yolo v2增加了在ImageNet上使用448x448输入来finetune的步骤，使模型可以适应检测数据上的高分辨率输入。 使用高分辨率后，mAP提高了4% 卷积预测+Anchors 更换FC层预测为Conv预测，同时使用anchor box。 Yolo v2采用416x416的输入，stride为32，是为了保证最后feature map的大小为奇数（13x13），其包含一个中心点，对于一些大物体，中心点通常落到图片的中心位置，使用feature map中心点去预测这些物体会相对容易。 Yolo v2对于每一个anchor box都独立预测一套分类概率 使用anchor之后，召回率提高了7% 边界框聚类分析 Yolo v2使用K-means，对训练集中的边界框使用box与中心box的IOU值作为指标进行聚类分析，改善在Faster RCNN和SSD中人工设定先验框的主观性。Yolo v2最终选取5个聚类中心作为先验框。 对于不同的数据集可以分析出更合适的先验框尺度，可以更贴近数据集中gt的尺度。 使用聚类分析后，mAP提高了0.4% DarkNet-19 使用特征提取网络，抛弃GoogLeNet结构。 DarkNet-19使用19个卷积层和5个max pool层，使用7个1x1卷积来减少参数/计算量。最后一层使用global avgpooling（滑窗大小=feature map大小）。 计算量减少33% 位置预测限定 沿用Yolo v1的思想，预测边界框中心点相对于对应cell左上角的偏移量，相当于把中心点约束在当前的cell内。抛弃无约束的位置预测。 其中，bx，by，bw，bh分别为feature map上预测框的中心点坐标和宽高；cx，cy为cell左上角的坐标（每个cell的大小都为1x1）；tx，ty，tw，th分别为预测的坐标偏移量；pw，ph为先验框的宽高；W，H为特征图的大小。img_w，img_h为原始图的宽高。 边界框的最终位置为：bx / W * img_w，by / H * img_h，bw / W * img_w，bh / H * img_h 使用该约束预测 + 聚类分析，mAP提升5% pass through层 pass through层将DarkNet-19中最后一个max pooling层的输入（26x26x256）进行pass through变换操作得到（13x13x2048）,与输出（13x13x1024）进行连接得到（13x13x3072）,然后卷积在该特征图上进行预测。 该操作使mAP提高了1% 多尺度输入训练 采用不同大小的图片作为输入，使其可以适应多种大小的图片输入。 每个10个迭代周期，随机选择一种输入大小（必须为32的倍数，如320，352…608），同时对最后检测层进行修改后训练。 how 训练过程 阶段一，使用输入大小为224x224，在ImageNet分类数据集上对DarkNet-19进行预训练。 阶段二，调整输入大小为448x448，继续在ImageNet分类数据集上对DarkNet-19进行fine-tune。 阶段三，修改分类模型为检测模型，在检测数据集上进行fine-tune。网络修改包括（网路结构可视化）：移除最后一个卷积层、global avgpooling层以及softmax层，并且新增了三个 3x3卷积层，同时增加了一个passthrough层，最后使用1x1卷积层输出预测结果。 损失函数 第一部分为，背景（iou小于设定阈值）的置信度误差。 第二部分为，先验框与预测框的坐标误差，只在前12800次迭代中计算。 第三部分为，计算与gt匹配的预测框的各部分的loss，坐标误差，置信度误差，分类误差。一个gt只匹配一个预测框，其余的大于iou阈值的预测框的loss不计算。而且Yolo v1中使用平方根降低box大小对loss的影响，Yolo v2使用权重稀系数来控制loss，尺度小一些的box的权重高一些。 总结 加了很多其他文章的点，性能提升很多，但是对小物体不友好的情况仍然没有改善。 Yolo9000 提出了一种分类和检测联合训练策略。对于检测数据集，可以用来学习预测物体的边界框、置信度以及为物体分类，而对于分类数据集可以仅用来学习分类，但是其可以大大扩充模型所能检测的物体种类。 因为检测和分类两者类别并不完全互斥，所以作者提出了一种层级分类方法。即根据各个类别之间的从属关系立一种树结构WordTree。 WordTree中的根节点为”physical object”，每个节点的子节点都属于同一子类，可以对它们进行softmax处理。在给出某个类别的预测概率时，需要找到其所在的位置，遍历这个path，然后计算path上各个节点的概率之积。 在训练时，如果是检测样本，按照YOLOv2的loss计算误差，而对于分类样本，只计算分类误差。在预测时，YOLOv2给出的置信度，边界框位置，一个树状概率图。在这个概率图中找到概率最高的路径，当达到某一个阈值时停止，就用当前节点表示预测的类别。","link":"/2019/05/11/Yolov2-CVPR2017-Detection/"},{"title":"常见的树结构","text":"一、常见的树结构1. 二叉搜索树 定义：对于任意一个节点，左子树比根节点小，右子树比根节点大 特性：平衡状态下时间复杂度为O(log n)，当插入数据有序时，查询复杂度为O(n) 2. 平衡二叉树 定义：在二叉搜索树基础上增加任何一个节点左子树和右子树深度差小于等于1 特性：查询复杂度为O(log n)，可以避免二叉树查询复杂度退化为O(n) 3. 红黑树 定义：在二叉搜索树基础上限制，根节点为黑色，每个节点要么红要么黑，红节点的子节点一定是黑节点，叶子节点和空节点为黑节点，从红黑树的任意一节点出发到叶子节点经过的黑节点个数相同，新插入的节点为红节点可能在平衡操作之后变黑 插入规则：遇到不满足红黑树条件的时候，首先判断当前节点的父节点和叔叔节点是否都为红色，如果都为红色，直接变色（父节点和叔叔节点变为黑色，爷爷节点变为红色），然后以爷爷节点为当前节点继续判断。如果当前节点没有叔叔节点或叔叔节点为黑色，那么判断当前节点是LL、LR、RR、RL，如果是LL或RR，则直接变色（父亲节点变为黑色，爷爷节点变为红色）并右旋或左旋。如果是LR或RL，则先把它们通过右旋或左旋变换为LL或RR，再进行变色旋转操作。具体树结构变换可参考该博客。 删除规则：（无子节点，有一个子节点，有两个子节点） X （红色，黑色），具体树结构变换可参考该博客。 特性： 相较于平衡二叉树的平衡条件要宽松很多，节省了插入节点时的部分变换耗时，最多旋转3次实现平衡，牺牲写入性能解决退化为链表的场景，时间复杂度O(log n) 4. B树 定义：多路平衡查找树，在平衡二叉树基础上允许每个节点有更多子节点。专为外部存储器设计比如文件系统及数据库，读取和写入大块数据有较好性能。B树的每个节点大小一般相同为磁盘一页。 特性：二叉树划分为2个区间，B树将范围划分为多个区间，降低了树的高度，数据定位更快，且跟磁盘IO读取特点相结合（磁盘一次读取一页连续数据，包含若干个block），有效降低了磁盘IO，根节点一般在内存中，通过二分法找到下层节点，磁盘IO一次读取下一个节点到内存中。时间复杂度为O(log n)。 5. B+树 定义：B+树是B树的变体，约定所有的关键字都存储在叶子节点，并为所有叶子节点增加了一个链指针。 特性：B+树可以更好地利用空间局部性原理，利用磁盘预读原理提前将当前读取数据相邻数据读入内存，减少磁盘的IO次数；同时叶子节点的链表式设计可以更快的范围查询。时间复杂度为O(log n)。 二、HashMap为什么选择红黑树？ 说明：Java8之前，HashMap使用数组+链表；Java8及之后，HashMap在容量超过8之后使用红黑树。 时间复杂度：二叉搜索树在有序场景下会退化为O(n) 树结构变换成本：红黑树的平衡条件宽松，节省了平衡二叉树节点变换的部分成本；同时B树和B+树结构的变换成本较高，需要进行节点分裂合并等操作；而红黑树进行简单节点旋转即可。 HashMap特性：HashMap是基于内存的数据结构，B树和B+树更适用于磁盘存储，因此选用红黑树更合适，其中8是经验值，可以通过loadFactor调整。 三、MySQL索引为什么选择B+树？ 场景特性：索引本身很大，无法全部存在内存中，所以需要以文件形式存在磁盘上，因此索引查询过程中磁盘IO是很大的消耗，因此索引的数据结构应该选择可减少磁盘IO的树结构，减少IO成本；B+树非叶节点中不包含指针数据，在磁盘相同读取的条件下，B+树可以读取更多的索引数据，从而减少可能的磁盘IO。 时间复杂度：B+树内节点不存储数据，所有数据存储在叶节点即查询时间复杂度固定为O(log n)，时间复杂度是稳定的，而B树查询的时间复杂度不稳定。 空间局部性原理：基于磁盘读取的特性以及空间局部性原理，如果存储器某个位置被访问，那他附近的位置也会被访问，平衡二叉树及红黑树存储结构中相邻数值可能在存储结构上相差很远，而B+树可以很好利用空间局部性原理。 四、推荐网址推荐数据结构可视化网址","link":"/2021/02/23/MySQL%E7%B4%A2%E5%BC%95%E5%BC%95%E5%87%BA%E7%9A%84%E6%A0%91%E7%BB%93%E6%9E%84/"},{"title":"Spring Bean生命周期","text":"一、Spring Bean和Java普通对象的区别 Java普通对象生命周期比较简单，通过使用new关键字进行对象实例化后该对象可以被使用，该对象的生命周期由JVM管理，当该对象不再被使用时由Java自动进行垃圾回收，简单说普通Java对象的生命周期为：对象实例化 -&gt; 垃圾回收 Spring Bean生命周期由Spring IOC容器统一管理，由IOC容器进行Bean实例化，属性填充，初始化等管理，生命周期完全由容器控制，即实例化 -&gt; 属性填充 -&gt; 初始化 -&gt; 销毁。 二、Spring Bean生命周期 Spring Bean的生命周期指singleton bean，对于prototype bean，Spring在创建好交给使用者后不会再管理后续的生命周期。 1. 实例化 通过loadBeanDefinitions方法找到程序中所有的bean，并将其都放入容器的beanDefinitionMap中。 123456789101112131415161718@Overridepublic void registerBeanDefinition(String beanName, BeanDefinition beanDefinition) throws BeanDefinitionStoreException { ... if (hasBeanCreationStarted()) { // Cannot modify startup-time collection elements anymore (for stable iteration) synchronized (this.beanDefinitionMap) { // 将beanDefinition存入beanDefinitionMap this.beanDefinitionMap.put(beanName, beanDefinition); List&lt;String&gt; updatedDefinitions = new ArrayList&lt;&gt;(this.beanDefinitionNames.size() + 1); updatedDefinitions.addAll(this.beanDefinitionNames); updatedDefinitions.add(beanName); this.beanDefinitionNames = updatedDefinitions; removeManualSingletonName(beanName); } } ...} 遍历beanDefinitionMap，通过createBeanInstance方法创建bean实例 1234567891011121314151617181920212223242526public void preInstantiateSingletons() throws BeansException { ... // Iterate over a copy to allow for init methods which in turn register new bean definitions. // While this may not be part of the regular factory bootstrap, it does otherwise work fine. List&lt;String&gt; beanNames = new ArrayList&lt;&gt;(this.beanDefinitionNames); // Trigger initialization of all non-lazy singleton beans... for (String beanName : beanNames) { RootBeanDefinition bd = getMergedLocalBeanDefinition(beanName); if (!bd.isAbstract() &amp;&amp; bd.isSingleton() &amp;&amp; !bd.isLazyInit()) { ... getBean(beanName); } } ...}protected Object doCreateBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException { ... // Instantiate the bean. if (instanceWrapper == null) { instanceWrapper = createBeanInstance(beanName, mbd, args); } ...} 构造对象createInstance，利用反射机制从Bean定义中的BeanClass拿到对应类的构造方法 bean中有一个构造方法则默认取他 bean中有多个构造方法则优先拿@Autowired注解的构造方法；多个构造方法都加注解则报错；多个构造方法都没有@Autowired方法则默认取无入参的构造方法；多个构造方法都是有入参的则报错。 在单例池中根据以上构造方法的参数进行class类查找 通过反射进行bean的构造-实例化 2. 属性填充 通过populateBean方法为Bean内部需要的属性进行赋值填充. 12345678910111213protected Object doCreateBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException { ... // Initialize the bean instance. Object exposedObject = bean; try { populateBean(beanName, mbd, instanceWrapper); exposedObject = initializeBean(beanName, exposedObject, mbd); } catch (Throwable ex) { ... }} 3. 初始化 通过initializeBean方法对bean实例进行初始化 12345678910111213141516171819202122232425262728293031323334protected Object doCreateBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException { Object exposedObject = bean; try { // 属性注入 populateBean(beanName, mbd, instanceWrapper); // Bean初始化 exposedObject = initializeBean(beanName, exposedObject, mbd); } catch (Throwable ex) { ... } ...}protected Object initializeBean(String beanName, Object bean, @Nullable RootBeanDefinition mbd) { ... // 为实现了各种Aware接口的bean设置容器信息（beanName，beanFactory等 ） invokeAwareMethods(beanName, bean); applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); ... try { // 执行bean的初始化方法（对应Bean中实现IntializingBean接口而实现的afterPropertiesSet方法），执行bean上自定义的initMethod方法 invokeInitMethods(beanName, wrappedBean, mbd); } catch (Throwable ex) { ... } applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); ... } 4. 销毁 通过registerDisposableBean方法将实现了销毁接口DisposableBean的Bean进行注册，这样在销毁时会执行destory方法 12345678910111213protected void registerDisposableBeanIfNecessary(String beanName, Object bean, RootBeanDefinition mbd) { AccessControlContext acc = (System.getSecurityManager() != null ? getAccessControlContext() : null); if (!mbd.isPrototype() &amp;&amp; requiresDestruction(bean, mbd)) { if (mbd.isSingleton()) { // Register a DisposableBean implementation that performs all destruction // work for the given bean: DestructionAwareBeanPostProcessors, // DisposableBean interface, custom destroy method. registerDisposableBean(beanName, new DisposableBeanAdapter( bean, beanName, mbd, getBeanPostProcessorCache().destructionAware, acc)); } ... }} 销毁前先执行postProcessBeforeDestruction（对应执行bean中的@PreDestory方法） 通过destoryBeans方法逐一销毁所有的bean（对应执行每个bean的destory方法），destory执行后会通过invokeCustomDestoryMethod执行bean上自定义的destoryMethod方法 三、Spring Bean相关延伸1. AOP1.1 . AOP原理 spring启动创建IOC容器初始化阶段通过Bean后置处理器DefaultAdvisorAutoProxyCreator进行方法增强，每个bean初始化之后都会调用其postProcessAfterInitialization方法，在方法中会为使用AOP的bean创建代理对象，通过getAdvicesAndAdvisorsForBean方法获取所有的增强Advice同时判断当前bean是否满足切面条件；其中proxyFactory是专门用来构造生产代理对象的工厂（可以在Application上添加@EnableAspectAutoProxy(prooxyTargetClass=true)来强制使用cglib） JDKProxy：JDKProxy会在getProxy中构造一个实现同样bean接口的代理对象，将真实bean作为代理对象中的一个成员变量，在执行bean方法的时候会执行代理对象中的invoke方法（获取所有满足条件的增强advice组成调用链，顺序执行调用链，经典的责任链模式） cglibAopProxy：用增强器Enhancer来设置代理基本信息及增强方法的调用链；执行enhancer#create()方法来生成代理对象。cglib基于jdk rt jar包中的ASM来生成一组新的.class文件，然后实例化它的对象，所以没有实现接口的bean也可以生成代理对象；在调用bean方法的时候回显执行代理对象的intercept方法（通过责任链执行所有的方法增强） 1.2. Spring AOP和AspectJ AspectJ框架：静态代理，在代码运行前通过修改class文件来实现代理，有以下三种方式。 编译时：在编译时通过AspectJ编译器重新编译生成一个新代理类，把新类作为一个正常的类装载到JVM中 编译后：通过字节码增强技术重新构建class和jar文件，通常在代理第三方jar的时候使用 加载时：在jvm加载类的时候植入代理 Spring AOP：动态代理，在代码运行时进行代理，有以下两种方式。在spring中如果主类实现了任意接口则使用jdk proxy，否则使用cglib；在springboot中无论任何情况都默认使用cglib进行代理 cglib方式：通过字节码技术在运行时生成主类的代理类 jdk proxy方式：通过实现主类接口，构造一个伪装为主类的代理类，约束：要代理的主类必须实现接口。 2. 三级缓存 三级缓存，解决循环依赖问题 singletonObjects：单例缓存，存放初始化好的bean earlySingletonObjects：存放仅实例化的bean对象（未填充属性） singletonFactories：存放bean工厂对象 Spring无法解决的依赖 构造器注入形成的循环依赖 prototype+singleton场景注入的循环依赖 1234567891011121314151617181920212223242526protected Object getSingleton(String beanName, boolean allowEarlyReference) { // Quick check for existing instance without full singleton lock Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) { singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null &amp;&amp; allowEarlyReference) { synchronized (this.singletonObjects) { // Consistent creation of early reference within full singleton lock singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null) { singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null) { ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) { singletonObject = singletonFactory.getObject(); // 将对象放入earlySingletonObjects并从singletonFactories中移除 this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); } } } } } } return singletonObject;}","link":"/2022/09/23/Spring%20Bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/"},{"title":"MySQL原理浅析","text":"一、模块分布 连接驱动，连接池（关键参数：最大链接数量，单次最大数据报文） SQL接口，SQL解析器，SQL优化器 存储引擎（对优化后的SQL进行执行），存储分为内存和硬盘，InnoDB，MyISAM，Cluster，Falcon 二、数据写入1. 写入流程 一切逻辑处理和读写操作都操作内存中数据 – Buffer pool，数据写入过程如下 为支持回滚，数据旧值会存储在Undo log中 将数据新值写入Buffer Pool中，并在合适的时间由innodb提供的线程写入磁盘中 为防止断电后写入内存中的数据丢失，innodb设计了redo log（内存中）存放 更新写入信息，并植入至redo log日志文件中（磁盘），此处有多种刷盘策略 ；在机器故障重启后会优先从redo log中将未刷盘的数据写入来保证数据的完整性 策略0：将更新写入信息 -&gt; Redo log buffer -&gt; 每隔1s写入系统page cache并刷盘。该策略在MYSQL挂了或者系统宕机时可能会有1s的数据丢失。 策略1：在事务提交前，将更新写入信息 -&gt; 在事务提交时，Redo log buffer -&gt; 操作系统page cache中 -&gt; flush磁盘。该策略在MYSQL挂了或者系统宕机时，日志丢了，但是事务未提交，数据具备一致性。 策略2：将更新写入信息 -&gt; Redo log buffer和系统page cache -&gt; 每隔1s写刷盘。该策略在MYSQL挂了的场景下没有影响，在系统宕机可能会有1s的数据丢失。 2. 存储结构 新表创建，会在磁盘data目录下生成xx.frm文件（存储表结构信息）和xx.idb文件（表空间文件，用来存储表数据和索引，5.7之前所有表的数据和索引都存放在系统表空间，5.7之后会为每张表创建独立表空间） 5类表空间：独立表空间，系统表空间，undo表空间，通用表空间，临时表空间。独立表空间相比系统表空间具有可压缩，可传输等优势 页：InnoDB读取写入数据的单位是页（16k，内存对齐，与B+索引树中节点对应，共有12种页结构），是innoDB内存和磁盘交互的最小存储单元，每个页内部地址连续 行：最大大小为8kb但大小不固定 区：大小固定为1M，存放64个地址连续的页，在跨页读相关数据的情况大概率都在附近地址，很少出现磁头移动；对于读取频繁的区会将整个区放入buffer pool内存中了；对于新建表默认会创建6个页（前4个分别记录 了表空间和区组条目信息，change buffer信息，段信息，索引根信息），不为一个区，共占96k，8.0版本后会创建7个页，这些也会放在表空间的碎片区中；当存储需求越来越大，会不断创建新的页空间，直到构建了32个零散页之后，后续每次都会申请完整的区。 组：方便区的管理，每个组管理固定的256个区即256M；第一个组的第一个区的前四个页保存了表空间和区组条目信息，change buffer信息，段信息，索引根信息，其他组的第一个区的前两个页保存了区组条目信息和change buffer相关信息 段：逻辑概念，不对应物理结构，用来区分不同功能区和碎片区中的页，分为叶子节点段（存储和管理实际数据）和非叶子节点段（存储和管理索引树），对应B+树中的叶子和非叶子节点 2. 执行原理 客户端与服务端建立链接，获取SQL语句。客户端（连接驱动）和服务端（连接池）的使用半双工模式通信 根据SQL语句查询 DB的查询缓存（map结构，key为sql语句，value为查询结果），由于多数情况下查询条件都不相同，会导致缓存命中率低，所以在8.0版本后去掉了查询缓存 sql解析器 词法分析。sql词法分析结合symbols数据对sql语句进行关键词，非关键词标记 语法分析 bison。将规则解析为一个语法树，并进行正确性验证（关键字，关键字顺序等） 预处理器。先提交SQL模板语句，再提交参数进行执行；对于多次重复执行的语句可以只提供一次SQL模板，提供多次SQL参数即可；语法验证（表和列是否存在，别名歧义验证等） SQL优化器。通过基于成本的优化器CBO，从目标诸多执行路径中选择成本最小的执行路径作为执行计划。（成本指数据表，数量，索引等信息计算出SQL语句对应的IO成本消耗值和CPU成本消耗值）；优化策略：关联查询重排，索引优选，链接查询重组，优化排序，优化max/min函数，提前终止查询，等价变化等。 SQL执行器。根据以上提供的执行计划，查询相关的Handler API进行组合和调用，将查询结果通过TCP协议返回给客户端 InnoDB执行过程。将Handler API传入命令进行微事务拆解MTR（原子访问）。 读指令。先去buffer pool通过 自适应哈希索引AHI 进行查找并返回（innodb会根据一些规则为热点页建立AHI）；buffer pool中未找到对应数据，则通过预读方式将相关数据从磁盘表空间加载到buffer pool中，返回数据读指令结果。buffer pool会通过free链表，flush链表，LRU链表管理数据页的写入位置，刷盘位置及数据页淘汰。 写指令。先写入负责事务回滚的undo log，然后将数据记录写入redo log buffer中，并根据一定策略将数据刷入磁盘redo log中（保证断电等情况下将尚未刷到磁盘中的数据做恢复）；将真实数据写入buffer pool，同时根据一定规则判断是否要写入change buffer中，写入change buffer后将在后续某时机合并到buffer pool中，真实数据写入buffer pool后会找时机将内存中数据刷入磁盘中；为保证页的完整传输会先将数据写入double write buffer中，同时写入磁盘中 系统表空间 的double write中（在页传输到一半时出现问题，磁盘上产生了残缺的页也可以通过double write进行恢复）；double write写完后将真实数据刷入磁盘就完成了写指令。 innodb中的其他模块，内存：锁信息区（锁信息），数据字典区（字典信息），additional memory pool（内部共享信息）；磁盘：通用表空间，临时表空间 三、日志1. bin log-二进制日志 bin log提供变更历史查询，数据库备份和恢复，主从复制等功能；在redo log写入同时，对binlog进行刷盘。binlog在事务提交的时候一次性写入，在事务提交时将日志写入cache中，事务提交的时候将cache一次性写入binlog文件 STATEMENT方式：记录变更SQL的SQL语句；相比ROW方式无需存储数据变更行的明细，存储量相对较小；但对于包含部分函数的语句无法保证数据一致性，比如UUID，rand等；同时需要记录SQL执行时的一些上下文信息。 ROW方式：记录实际变更的数据行；无需记录SQL变更时的上下文信息，数据一致性得到保障；但当ALTER，UPDATE较多数据行时会产生大量的日志内容。 MIXED方式：以上两种方式的融合，数据行变更多且不会产生数据一致性问题的语句用STATEMENT方式比如表结构变更，rand函数等，其他用ROW方式，两者兼顾。 2. redo log - 重做日志 redolog保证事务的持久性。在DB故障时如果数据更新操作写入了buffer pool中但还未写入磁盘中，DB重启后会根据redolog恢复内存中的数据至磁盘中。 redolog记录物理数据页面的修改信息；redolog大小固定，采用环形数组形式，循环擦除记录；事务开始之后开始写入redolog，对应事务的数据写入至磁盘后，redo log的空间可被覆盖重用。 3. undo log - 回滚日志 undolog保证事务的原子性。保存事务发生之前数据的一个版本，可用于回滚。在真实数据行中会使用roll_pointer关联undo log信息， 写入时间：在事务中，每个SQL通过执行器后会在回滚段中申请一个undo log页，根据sql信息构建undo log内容？同时将其写入磁盘，保证每次操作真正数据前undo log完整；undo log写入完成后才会执行内存数据写入，记录redo log，数据刷盘等操作。 大小个数限制：按每页4kb，默认共有128个回滚段，每个回滚段可创建1024个undolog页 日志格式：根据增删改分为不同的日志格式类型；新增操作记录的undo log日志在事务提交之后可直接删除，删除和更新的undo log需要用于MVCC；undolog为节省空间会设定一定的重用机制。 四、InnoDB页1. 简介 页是innodb管理数据和磁盘交互的基本单元，默认16kb，需要保证他是操作系统 数据块 4KB的整数倍（在读写操作中保证数据块的完整，不被分割浪费） 数据页的构成：页头，页尾，数据行 页头：总体占用38字节，页号-全局唯一，占用4个字节；上下页的页号，组成双向链表；页类型，表空间ID，最近一次修改的LSN，已经被刷到磁盘的LSN（日志序列号），校验和（做完整性校验，默认使用crc32验证算法验证）。 页尾：总体占用8字节，校验和，最近一次修改的LSN 数据行：与表中的数据行对应，每个数据行通过next_record字段构成一个单向链表；为加速数据行的查询效率，在页结构中构建了page direction页目录，存储数据行组（每8个数据行为一个组）的最后一个数据行在页中的地址，后续数据行的查询可以使用页目录进行二分查找。 数据行中Null值节省空间的存储方式：数据行中数据为Null的列，会单独放在数据行头部信息的 Null值列表 （由可为Null的列组成，没割裂占一个bit位，该行中该列为空则为1，不为空则为0） 数据行的类型：DYNAMIC，COMPRESSED（与DYNAMIC相结构相同，不过会对数据进行压缩），COMPACT（与DYNAMIC在超长字段的处理上有一些区别，不会把所有超长字段都放入溢出页中） 2. 索引结构 平衡二叉树：数据量大的情况下，树的高度较高，查询成本高；且平衡要求严格，插入的变换成本高；查询效率不稳定。 B树：查询单值场景效率高（可以通过degree降低树的高度），但是范围查询效率低（相邻数值可能在结构上可能相差很远），查询效率不稳定（取决于离根节点的远近） 红黑树：范围查询问题；数据量大后查询成本问题（本质上还是而平衡二叉树，只是平衡条件宽松了，意味着树的高度跟平衡二叉树相似）；查询效率不稳定。 B+树：将所有数据都放在叶子节点，可以保证每次查询的稳定性（都需要走树的高度）；非叶子节点不存放实际数据，意味着可以存放更多的索引信息（16kb页通常可存储300/400个key和下一页地址的行 ）；将叶子节点的数据链接，可以解决范围查询的问题 3. 聚簇/非聚簇索引 聚簇索引又称为 一级索引， 在表创建时自动创建，主键设定（业务主键 -&gt; 业务唯一键 -&gt; 数据库自动生成的db_row_id） 非聚簇索引又称为二级索引，索引中除去一级索引外的其他索引。非聚簇索引的结构中仅保存主键及聚簇索引key；查询过程：根据key在非聚簇索引中查找到对应聚簇索引的key，再去聚簇索引树中查找对应的实际数据 回表？ 五、事务 定义：将多个数据库操作打包成一个不可分割的整体来执行，要不全部执行，要不全不执行，以保证数据的可靠和一致性。START TRANSACTION：开启事务；COMMIT：提交事务。 1. ACID模型原子性，隔离性，持久性保证最终的一致性。 原子性：借助undo log实现，当事务中的某个操作执行失败时，会按照undo log中的记录反向执行，将数据恢复。 隔离性：指事务执行过程中相互隔离，不能相互干扰，不能查看相互间未提交的数据。主要分为写+写隔离（通过锁实现），写+读隔离（通过MVCC实现） 持久性：事务一旦提交，事务中的所有更改不会因为电源故障，系统崩溃等意外发生变化。 写入buffer pool但未写入磁盘时故障，借助redo log实现。 在数据刷盘过程中故障，默认以16kb大小的数据页刷盘，而操作系统每次以4kb大小进行数据传输，存在数据页只传输一部分情况，这里借助双写缓冲区，通过他的同步机制来解决。 一致性 多个事务同时执行会出现的三大明显问题。 脏读，不可重复读，幻读 四种隔离级别 读未提交：读取数据时采用当前读模式，更新数据时采用共享行锁 读已提交：在事务读取数据时不加锁，但使用快照读（MVCC），更新数据采用独占行锁 可重复读：不加锁使用快照读，更新数据时采用next-key行锁 串行读：事务读取时添加共享表锁，数据更新时添加独占表锁 2. 锁机制2.1 锁模式 共享锁（读锁，LOCK IN SHARE MODE）：一个事务添加了共享锁后，其他事务还可重复添加共享锁，但无法添加排他锁。 独占锁（写锁，排他锁，FOR UPDATE）：在当前加锁事务释放前，其他事务无法为数据加任何锁 共享意向锁：上锁时在数据所在表上做标记，其他事务为表加锁前无需遍历每条数据判断是否有锁 独占意向锁：同上 自增锁：表锁，为配置了AUTO_INCREMENT的列服务，在插入数据时会增加自增锁，生成自增值，同时阻塞其他的插入操作，以保证值的唯一。 2.2 锁类型 表锁，行锁 2.3 行子类型 精准行锁：精准锁住对应的行数据 GAP锁：锁住行与行之间的间隙，防止在间隙中插入数据 Next key锁：以上两种锁的组合 插入意向锁：共享锁，如果一个行间隙加了GAP锁，其他事务想在这个行间隙插入数据会加插入意向锁，多个事务都可以加锁，当GAP锁释放后允许多个插入意向锁同时进行插入，以提升插入效率。 2.4 MVCC机制 多版本并发控制机制，在读取数据时利用类似数据快照的形式将数据保存下来，以保证读锁和写锁不冲突，通过undo log版本链和readview读视图来实现的。","link":"/2022/06/23/MYSQL%E5%8E%9F%E7%90%86%E6%B5%85%E8%AF%BB/"},{"title":"Java基础之JVM","text":"一、JVM概念JVM（Java Virtual Machine，Java虚拟机）是Java程序运行的环境，主要任务是在运行Java程序时，负责解释Java字节码并将其转换为机器码，然后交给CPU执行，同时JVM还负责管理Java程序的运行时数据区、类加载机制和垃圾回收等。 JVM的架构由三个部分组成：类加载器、运行时数据区和执行引擎。类加载器负责将Java字节码装载到JVM中，并在需要时解析和链接它们。执行引擎从方法区/元空间获取类的结构信息和代码，并在运行时数据区的虚拟机栈中创建栈帧，执行方法。运行时数据区是执行引擎执行方法时的内存空间，包括方法区/元空间、堆、虚拟机栈、本地方法栈和程序计数器等，为执行引擎提供内存空间。JVM还包括其他组件，如垃圾收集器、安全管理器等。 二、类加载器1. 类加载机制1.1 类包含的基础元素以下元素以类加载及对象实例化过程中先后顺序排序，且构造方法及实例方法需要通过对象调用。 静态变量：用于描述类的属性，所有对象共享同一个静态变量副本。类加载阶段。 静态代码块：用于在类加载时执行一些初始化操作，例如初始化静态变量或读取配置文件等，在类加载的时候执行一次。类加载阶段。 静态方法：可以访问类的静态变量和其他静态方法，不依赖于对象的存在。类加载阶段。 实例变量：用于描述某个对象的属性，每个对象都有一份独立的实例变量副本。对象实例化阶段。 实例代码块：用于对实例变量进行初始化，每次创建对象时都会执行。对象实例化阶段。 构造方法：用于创建对象，可以接受参数，初始化对象的实例变量。对象实例化阶段。 实例方法：用于实现类的功能，可以访问类的成员变量和其他方法，也可以接受参数并返回值。对象实例化阶段。 1.2 类加载过程JVM的类加载机制是将类字节码装载到内存中的过程。类加载机制分为加载、连接和初始化三个阶段。其中连接阶段包括验证、准备和解析三个过程。 1.1.1 加载ClassLoader通过类的全限定名找到对应类的字节码文件，将类二进制数据从文件或其他数据源读入到JVM内存的方法区中，并利用字节码文件创建class对象。 1.1.2 验证对元空间/方法区中的类二进制数据进行校验，以确保其符合JVM规范，并且没有安全上的问题。 1.1.3 准备在准备阶段，JVM会在元空间/方法区中为类的静态变量分配内存并将其初始化为默认值，不包含final static修饰的变量，final变量在编译时已分配。 1.1.4 解析将类的符号引用（例如变量名、方法名）解析为直接引用（例如内存地址），以便JVM能够正确地执行类的方法。解析阶段会使用到元空间/方法区中的常量池。 1.1.5 初始化为类的静态变量赋值，并执行类的初始化代码（例如静态代码块）。如果该类具有父类就先对父类进行初始化，执行其静态初始化器（静态代码块）和静态初始化成员变量。初始化阶段会使用到堆内存、元空间/方法区和虚拟机栈等JVM内存区域。 2. 双亲委派机制2.1 双亲委派介绍当一个类加载器要加载一个类时，它首先将该请求委派给父类加载器处理，如果父类加载器仍无法找到该类，则该请求再由当前类加载器自行处理。双亲委派机制中ClassLoader类中的三个重要方法，loadClass，findClass，defineClass。loadClass方法和findClass方法一起实现了双亲委派机制。loadClass方法会尝试在父类加载器、指定路径或者系统路径中查找指定的类文件，并返回对应的Class对象。如果存在父类加载器，该方法会先委托父类加载器加载，如果父类加载器无法完成加载，才会调用自身的findClass方法进行加载。findClass方法在指定的路径中查找指定的类文件，并返回对应的Class对象。如果自定义类加载器需要加载特殊的类文件，这个方法需要被子类实现。defineClass方法则用于将二进制数据转换成类对象。 2.2 双亲委派的好处 保证Java类库中的类可以正确加载，避免类文件版本不一致导致的类加载异常 保证了类的唯一性，避免相同类的被不同类加载器重复加载，提高了类的复用性，提高了Java程序的性能。 避免Java类库类被恶意替换的问题，保证了Java程序的安全性。 2.3 如何打破双亲委派Tomcat是一个Web服务器，它需要加载并运行Web应用程序，而这些Web应用程序可能包含自己的类和库，这些类和库可能与Tomcat中的类和库产生冲突，从而导致类加载的问题。因此Tomcat打破双亲委派机制，采用了自己的类加载器实现，避免了与Tomcat中的类和库产生冲突的问题。 打破双亲委派有多种方式比如自定义ClassLoader，使用线程上下文类加载器，使用Java反射机制调用ClassLoader的defineClass方法，手动将类加载到虚拟机中。下面举例常用方式-自定义ClassLoader，其中最重要的就是重写ClassLoader中的loadClass方法。 自定义ClassLoader类：自定义ClassLoader继承ClassLoader类，并重写findClass()方法。 实现findClass()方法：在findClass()方法中实现加载类的逻辑，即根据类名和类路径查找类的字节码，并通过defineClass()方法将字节码转换为Class对象。 打破双亲委派机制：在自定义ClassLoader中重写loadClass()方法，打破双亲委派机制，直接通过自定义ClassLoader来加载类。 三、JVM内存结构1. 划分内存结构原因 运行过程中不同数据有不同的生命周期，划分区域可定义不同区域的生命周期，节省内存使用开销。 提高内存的利用效率，划分内存区域可以提高内存的使用效率，避免内存碎片等问题。 提高GC的效率和减少GC的频率，划分内存区域可以更好地进行垃圾回收。 提供内存保护能力，对不同的内存区域进行访问控制，保护内存的安全性，避免了程序因为内存问题而崩溃或者被攻击的风险。 提供部分内存区域共享能力，JVM中的方法区和堆内存可以被多个线程共享，从而节省了内存的使用，提高了程序的效率。 2. 如何划分内存结构JVM内存结构包括堆内存、栈内存、元空间（Java8之前为方法区/永久代）、程序计数器等部分。其中堆内存用于存放对象实例，栈内存用于存放基本数据类型和对象的引用，元空间/方法区用于存放类信息和常量池，程序计数器用于记录执行的代码行数。 2.1 程序计数器 定义/作用：当前线程执行的字节码的行号指示器，程序分支，循环，异常处理等都依赖于计数器。 存储数据：java方法则存储当前执行的字节码指令的地址；本地方法(非Java语言对应方法)则为空。 生命周期：与线程生命周期一致。 是否线程私有：线程私有。 2.2 JAVA虚拟机栈 定义/作用：以栈形式控制记录Java方法执行的过程，方法调用对应入栈，方法执行完毕对应出栈。 存储数据：以栈帧形式存储，栈帧中包含局部变量表，操作数栈，动态链接，方法出口等信息。 局部变量表：存放编译期间可知的基本数据类型，对象引用(指针)，返回地址(指针)，在编译期间完成分配。 操作数栈：记录了方法执行过程中的中间结果，包括方法参数、临时变量和计算结果等，是一个后进先出（LIFO）的栈结构。操作数栈中的每个元素都是一个int、long、float、double、引用或returnAddress类型。当方法被调用时，操作数栈会被初始化为空栈。 动态链接：记录了当前栈帧所属方法的引用，包括方法名、类名、参数类型和返回值类型等信息。在方法调用过程中，栈帧中的动态链接被用于解析方法调用并将其转化为实际的方法调用。Java虚拟机通过动态链接实现了多态性，使得程序能够在运行时动态地解析方法调用，比如向上转型后进行方法调用时会将子类方法的引用计入动态连接中，从而实现多态。 方法出口：记录了方法调用返回时要返回到哪个指令继续执行的信息，记录下一条指令的地址和当前方法的栈帧指针。这里方法出口跟程序计数器在方法调用时保存的信息会有所重复。 生命周期：与线程生命周期一致。 是否线程私有：线程私有。 2.3 本地方法栈 定义/作用：以栈形式控制记录本地方法执行的过程，方法调用对应入栈，方法执行完毕对应出栈。 存储数据：本地方法存储当前执行的字节码指令的地址。 生命周期：与线程生命周期一致。 是否线程私有：线程私有。 2.4 JAVA堆 定义/作用：用于存放对象实例，也是垃圾收集器管理的内存区域，物理空间上可处于不连续的内存空间中但逻辑上连续；为了提升对象分配时的效率java对会分配多个线程私有的TLAB。 存储数据：存放对象实例，数组对象，类实例，垃圾回收标志，运行时常量池等等信息。 生命周期：与JVM生命周期一致。 是否线程私有：线程共享。 2.5 元空间 存储数据：类的元数据信息，类的字节码数据，常量池，静态变量，方法元信息。 生命周期：与JVM生命周期一致。 是否线程私有：线程共享。 四、GC机制JVM自带了垃圾回收机制，可以自动回收不再使用的内存空间。垃圾回收机制可以分为分代收集，标记-清除、复制和标记-整理等算法。 1. 回收数据及条件JVM垃圾回收主要回收的是堆内存中的对象实例以及引用。同时其他类型的数据也会被回收，后续仅讨论Java对象的垃圾回收。 对象实例及引用：堆内存中，一个对象没有任何引用指向它或不再与任何对象之间存在引用链时，该对象实例会被回收。 类的类型信息：元空间中，当一个类不再被任何对象实例引用时，其类型信息会被回收。 常量池：元空间中，当一个常量不再被任何对象使用时，常量池中的该常量会被回收。 类的静态变量：元空间中，当一个类不再被任何对象实例引用时，其静态变量会被回收。 本地方法栈中的变量：本地方法栈中，当本地方法结束时，其中的变量会被回收。 程序计数器中的值：虚拟机栈中，当方法结束时，程序计数器中的值会被回收。 2. 如何判断可回收Java对象是否可回收的判断策略：可达性分析算法。可达性分析算法是通过GC Roots对象来实现的，GC Roots对象是程序中某一个时刻稳定可达的对象，包括虚拟机栈中引用的对象、本地方法栈中引用的对象、静态变量中引用的对象和常量池中引用的对象等，垃圾回收器会从GC Roots对象开始，遍历程序中的所有对象，标记所有可达对象，然后将未标记的对象视为垃圾，进行回收。 3. 内存回收的时机JVM垃圾回收时机是由垃圾回收器决定的，不同垃圾回收策略的回收时机不同。通常情况下，垃圾回收器会在以下情况下自动触发垃圾回收： 当堆内存空间不足时，垃圾回收器会自动触发垃圾回收，释放一些不再使用的对象，以便为新的对象腾出空间。 当程序中创建的对象数量超出了某个特定的阈值时，垃圾回收器会自动触发垃圾回收，阈值可通过JVM参数进行调整。 当程序中没有活跃的线程时，垃圾回收器可能会选择在此时触发垃圾回收。 当程序中显式调用System.gc()方法时，垃圾回收器也会触发垃圾回收，但这并不能保证垃圾回收一定会被执行。 4. 堆内存的划分JVM的堆内存主要分为年轻代和老年代两部分，其中年轻代又被划分为Eden区和2个Survivor区，HotSpot JVM年轻代Eden和Survivor比例为8:1，合理的设置Survivor和Eden大小可以有效地。堆区分代目的是为了提高GC效率，因为不分代的话GC需要进行全区扫描。 年轻代用于存放新创建的Java对象，包括JVM启动时创建的对象和程序运行时动态创建的对象。在划分年轻代时，会将其划分为一个Eden区和两个Survivor区。在Eden区中分配的对象，如果没有及时被垃圾回收器清理，就会移动到Survivor区中，经过多次垃圾回收后，如果对象仍然存活，则会被移动到老年代中。老年代用于存放长时间存活的Java对象，包括在年轻代多次垃圾回收后仍然存活的对象和大对象。年轻代的垃圾回收器通常采用复制算法，老年代的垃圾回收器通常采用标记-清除、标记-整理、或者是复合算法来进行垃圾回收。 5. 垃圾回收算法5.1 复制算法5.1.1 简介 将年轻代分为两区域：Eden区和两个Survivor区（一般为From和To）。 当Eden区满时，将其中存活的对象复制到其中From Survivor区中。 当Eden区和From Survivor区都满时会触发一次Young GC操作。Young GC会将Eden区和From Survivor区中的垃圾对象清理掉，并将存活的对象移动到To Survivor区，同时会对To Survivor区进行年龄判断和对象晋升，将年龄达到设定阈值的对象晋升到老年代中。 如果To Survivor区无法存放所有存活的对象，则会将部分对象直接晋升到老年代中。如果老年代也没有足够的空间来存放所有晋升的对象，则会触发一次Full GC操作，对整个堆内存进行垃圾回收。 5.1.2 特性 执行效率高：只需要遍历存活对象，不需要扫描整个堆内存，执行效率比较高； 没有内存碎片：复制算法每次只使用其中的一部分堆内存，不会产生内存碎片； 实现简单：复制算法的实现比较简单，并且不需要暂停整个应用程序。 需要额外的空间：复制算法需要额外的一部分空间来存储存活对象，会浪费一部分空间； 不适合存活对象多的情况：如果存活对象比较多，那么复制算法需要复制的对象也会比较多，这会降低执行效率。 需要暂停应用程序Stop-The-World（STW）：该算法在复制对象时，需要暂停整个应用程序的执行（新创建的对象可能会在复制过程中被复制器复制，可能导致对象状态不一致或丢失），会影响用户体验 5.2 标记-清除算法5.2.1 简介 从根对象开始遍历所有可访问的对象，并将它们标记为“存活”； 从堆中的所有对象中，遍历所有未被标记的对象，将它们标记为“需要清除”； 统一清除所有被标记为“需要清除”的对象； 将所有被标记为“存活”的对象状态重置为“未标记”； 5.2.2 特点 不需要额外的空间：标记清除算法不需要额外的空间来存储存活对象，因此不会浪费空间； 容易产生内存碎片，后续对象可能找不到可利用的内存空间 适合存活对象多的情况：如果存活对象比较多，那么标记清除算法不需要复制对象，因此不会降低执行效率。 执行效率低：标记清除算法需要扫描整个堆内存进行标记和清除，因此执行效率比较低； 需要暂停应用程序Stop-The-World（STW）：该算法在清除对象时，需要暂停整个应用程序的执行（为了确保垃圾回收器对堆内存的操作的正确性和一致性），会影响用户体验 5.3 标记-整理算法5.3.1 简介 从根对象开始遍历所有可访问的对象，并将它们标记为“存活”； 将所有被标记为“存活”的对象向堆的一端移动，并按照内存地址逐个紧凑排列，以释放出一段连续的内存空间； 将所有被标记为“存活”的对象状态重置为“未标记”； 释放所有未被标记的对象占用的内存空间。 5.3.2 特点 没有内存碎片：标记整理算法可以避免内存碎片，因为所有存活对象都会被紧凑排列； 不需要额外的空间：标记整理算法不需要额外的空间来存储存活对象，因此不会浪费空间； 适合存活对象分散的情况：如果存活对象分散在堆内存中，那么标记整理算法可以将它们“收拢”到一端，并释放出一段连续的内存空间，以供新对象使用。 执行效率低：标记整理算法需要将所有存活对象移动到一端，并按照内存地址逐个紧凑排列，因此执行效率比较低； 需要暂停应用程序：标记整理算法需要暂停整个应用程序的执行，以确保对堆内存操作的正确性和一致性。 6.常见垃圾收集器6.1 Serial收集器Serial收集器是JVM中最古老的垃圾收集器，它是一种单线程的收集器，使用复制算法。 优点： 实现简单，执行效率高； 可以与多种垃圾收集器结合使用。 缺点： 只能使用单线程，无法充分利用多核CPU； 在进行垃圾收集时，需要暂停整个应用程序的执行； 不适合用于大型应用程序。 6.2 ParNew收集器ParNew收集器是Serial收集器的多线程版本，它是一种并行的收集器，使用复制算法。 优点： 使用多线程，可以充分利用多核CPU，提高垃圾收集的效率； 可以与CMS收集器结合使用。 缺点： 在进行垃圾收集时，需要暂停整个应用程序的执行； 不适合用于大型应用程序。 6.3 Parallel收集器Parallel收集器是一种并行的收集器，它使用复制算法，并且可以自适应调整线程数，以提高垃圾收集的效率。 优点： 使用多线程，可以充分利用多核CPU，提高垃圾收集的效率； 支持并发标记清除、并发标记整理和并发标记压缩算法； 适合用于大型应用程序。 缺点： 在进行垃圾收集时，需要暂停整个应用程序的执行； 在CMS收集器的情况下，可能会产生内存碎片。 6.4 CMS收集器CMS收集器是一种并发的收集器，它使用标记清除算法，并且可以在应用程序运行时进行垃圾收集，以减少应用程序的暂停时间。 优点： 可以在应用程序运行时进行垃圾收集，以减少应用程序的暂停时间； 支持并发标记清除、并发标记整理和并发标记压缩算法； 适合用于大型应用程序。 缺点： 在进行垃圾收集时，会占用一定的CPU资源，可能会影响应用程序的性能； 可能会产生内存碎片。 6.5 G1收集器G1收集器是一种并发的收集器，它使用标记整理算法，并且可以按照堆内存的分区进行垃圾回收，以减少应用程序的暂停时间和内存碎片。 优点： 可以按照堆内存的分区进行垃圾回收，以减少应用程序的暂停时间和内存碎片； 可以逐步地将堆内存划分成多个区域，以提高垃圾回收的效率； 可以在应用程序运行时进行垃圾收集，以减少应用程序的暂停时间。 缺点： 在进行垃圾收集时，会占用一定的CPU资源，可能会影响应用程序的性能； 实现复杂，容易出现故障。 7. GC问题排查及优化策略7.1 Young GCEden区内存不足会触发Young GC，将Eden区及From区的未使用对象回收。 常见原因 新生代Eden和Survivor区设置比例不合理，Eden区设置过小，可能会导致新创建的对象在Eden无法存放，引发频繁Young GC。可以考虑调大新生代空间或根据对象创建频率及生命周期等特征调整Eden和Survivor区比例。 程序大量对象的创建，可能会导致新生代内存不足，引发频繁Young GC。这里需要从编码侧优化调整，尽可能对对象进行重用。 7.2 Full GC老年代内存不足会触Full GC，将新生代和老年代中所有未使用对象回收。常见原因有新生代不断进行Young GC后很多对象进入老年代，或者老年代中存在较大对象等等。 常见原因 老年代内存空间不足，可以通过调大堆空间及老年代空间来缓解频繁Full GC。 新生代转老年代的年龄阈值MaxTenuringThreshold设置过小（该参数默认15），导致部分短生命周期对象进入老年代导致老年代内存不足，引发Full GC。可以根据对象生命周期特征适当调整该阈值。 应用程序中大对象频繁创建，可能会引发频繁FullGC。可考虑通过优化代码将大对象信息存储在DB或文件中。 程序编码问题导致部分不再使用的对象未被释放，JVM会通过Full GC来释放堆空间避免OOM。需要优化程序编码对未使用对象及时释放。 五、JVM常用命令 jps：查看Java进程号。 jstat：监视JVM统计信息，如垃圾回收次数和持续时间、类加载、内存使用和线程情况等。 jstack：查看Java线程状态，分析线程堆栈信息，定位死锁和死循环等问题。 jmap：生成Java堆转储文件，用于分析内存泄漏、对象占用情况等问题。 jhat：分析jmap生成的Java堆转储文件，以图形化方式展示对象占用情况，帮助定位内存泄漏问题。 jinfo：查看JVM配置信息，例如JVM参数、运行模式等。 jcmd：JDK7新增的命令行工具，用于执行各种JVM操作，如GC、线程dump等。 jconsole：Java的图形化监控工具，可以监视JVM内存、线程、类加载、垃圾回收等情况，常用于性能调优和问题排查。 六、JVM性能调优JVM性能调优是指通过配置JVM参数、优化代码等方式来提高程序的运行效率和稳定性。常见的JVM性能调优包括调整JVM内存大小、选择GC算法、使用多线程等。 七、JIT优化技术JIT（Just-In-Time）是一种即时编译技术，可以将Java字节码转换成本地机器码，从而提高程序的执行效率。JIT优化技术包括栈上分配、逃逸分析、代码内联等。","link":"/2022/11/23/%E5%BF%85%E9%A1%BB%E4%BA%86%E8%A7%A3%E7%9A%84JVM%E7%9F%A5%E8%AF%86/"}],"tags":[{"name":"Video Detection","slug":"Video-Detection","link":"/tags/Video-Detection/"},{"name":"Tracking","slug":"Tracking","link":"/tags/Tracking/"},{"name":"Detection","slug":"Detection","link":"/tags/Detection/"},{"name":"DataStructure","slug":"DataStructure","link":"/tags/DataStructure/"},{"name":"Spring","slug":"Spring","link":"/tags/Spring/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"}],"categories":[{"name":"paper","slug":"paper","link":"/categories/paper/"},{"name":"blog","slug":"blog","link":"/categories/blog/"}]}